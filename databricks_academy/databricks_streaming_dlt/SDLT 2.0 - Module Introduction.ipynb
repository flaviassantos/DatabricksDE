{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef8ec813-39e8-467a-a17a-227a2d869793",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d72d63b0-36f9-4e52-9c88-a80cd3bd4d0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Streaming ETL Patterns with DLT\n",
    "This module is part of the Data Engineer Learning Path by Databricks Academy.\n",
    "\n",
    "#### Lessons\n",
    "Lecture: Data Ingestions Patterns <br>\n",
    "[SDLT 2.1 - Demo: Auto Load to Bronze]($./SDLT 2.1 - Auto Load to Bronze) <br>\n",
    "[SDLT 2.2 - Demo: Stream from Multiplex Bronze]($./SDLT 2.2 - Stream from Multiplex Bronze) <br>\n",
    "[SDLT 2.3 - Demo: Data Quality Enforcement]($./SDLT 2.3 - Data Quality Enforcement) <br>\n",
    "[SDLT 2.4L - Streaming ETL Lab]($./SDLT 2.4L - Streaming ETL Lab) <br>\n",
    "\n",
    "#### Prerequisites\n",
    "* Ability to perform basic code development tasks using the Databricks Data Engineering & Data Science workspace (create clusters, run code in notebooks, use basic notebook operations, import repos from git, etc)\n",
    "* Intermediate programming experience with PySpark\n",
    "  * Extract data from a variety of file formats and data sources\n",
    "  * Apply a number of common transformations to clean data\n",
    "  * Reshape and manipulate complex data using advanced built-in functions\n",
    "* Intermediate programming experience with Delta Lake (create tables, perform complete and incremental updates, compact files, restore previous versions etc.)\n",
    "* Beginner experience configuring and scheduling data pipelines using the Delta Live Tables (DLT) UI\n",
    "* Beginner experience defining Delta Live Tables pipelines using PySpark\n",
    "  * Ingest and process data using Auto Loader and PySpark syntax\n",
    "  * Process Change Data Capture feeds with APPLY CHANGES INTO syntax\n",
    "  * Review pipeline event logs and results to troubleshoot DLT syntax\n",
    "\n",
    "\n",
    "#### Technical Considerations\n",
    "* This course runs on **15.4.x-scala2.12**.\n",
    "* This course cannot be delivered on Databricks Community Edition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94131c7c-ee65-47cd-828d-f3dc1c2a3680",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "&copy; 2025 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark and the Spark logo are trademarks of the \n",
    "<a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "<br/><a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | \n",
    "<a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | \n",
    "<a href=\"https://help.databricks.com/\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "SDLT 2.0 - Module Introduction",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}